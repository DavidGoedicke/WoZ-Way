### WoZ Way
Interaction designers often have difficulty understanding people’s real-world experiences with ubiquitous systems. The automobile is a great example of these challenges, where on-road testing is time-consuming and provides little ability for rapid prototyping of interface behavior. In this demonstration, we show WoZ Way, a system to connect remote designers and researchers. This code provides the computing systems to give people the opportunity to "ride along" with a driver on the road while observing the drive, interacting through a machine speech system, viewing live car data, and controlling an in-car interface prototype.

### System Description
1. A Wizard interface with live video, audio, and data displays from the remote vehicle and controls to send text-to-speech messages to the driver or control the behavior of in-car prototypes
1. A mediating data server to manage communication between the remote vehicle and the Wizard interface; the data server also collects time-stamped data logs
1. A computer in the car to collect and share video, audio, and automotive data over the internet with the Wizard interface and to control spoken text-to-speech messages, screen interfaces, and electromechanical components
1. Auxiliary interfaces including screens, sensors, and actuators used in each specific study

### Suggested Citation
If you use any part of this code for your own research, please cite:

Nikolas Martelaro and Wendy Ju. 2017. WoZ Way: Enabling real-time interaction prototyping and on-road observation. _To appear CSCW ’17_.

### Authors and Contributors
This project was developed by @nikmart for his thesis work at Stanford's Center for Design Research.

### Support or Contact
Have any questions about this project or issues with the code? Email Nik at nikmart (at) stanford (dot) edu